{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "!pip install yapf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Multi-class Classifier on Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iris data and create train and test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "data = pd.read_csv('iris.data', names=cols)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample (shuffle) data | here frac=1 means 100% of data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width            label\n",
       "0           5.0          2.3           3.3          1.0  Iris-versicolor\n",
       "1           5.9          3.0           5.1          1.8   Iris-virginica\n",
       "2           5.7          3.8           1.7          0.3      Iris-setosa\n",
       "3           4.3          3.0           1.1          0.1      Iris-setosa\n",
       "4           5.8          2.7           5.1          1.9   Iris-virginica"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 5)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./input/train.csv')\n",
    "test.to_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload train csv to S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'arunprsh-sg-scikit-example'\n",
    "region = 'us-east-1'\n",
    "s3_session = boto3.Session().resource('s3')\n",
    "s3_session.create_bucket(Bucket=bucket)\n",
    "s3_session.Bucket(bucket).Object('train/train.csv').upload_file('./input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the Model script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sg_iris_train.py\n"
     ]
    }
   ],
   "source": [
    "%%file sg_iris_train.py\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "# Dictionary to convert labels to indices\n",
    "LABEL_TO_INDEX = {'Iris-virginica': 0, 'Iris-versicolor': 1, 'Iris-setosa': 2}\n",
    "# Dictionary to convert indices to labels\n",
    "INDEX_TO_LABEL = {0: 'Iris-virginica', 1: 'Iris-versicolor', 2: 'Iris-setosa'}\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    :param model_dir: (string) specifies location of saved model.\n",
    "    \n",
    "    This function is used by AWS Sagemaker to load the model for deployment. \n",
    "    \n",
    "    It does this by simply loading the model that was saved at the end of the \n",
    "    __main__ training block above and returning it to be used by the predict_fn\n",
    "    function below.\n",
    "    \"\"\"\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    :param request_body: the body of the request sent to the model. The type can vary.\n",
    "    :param request_content_type: (string) specifies the format/variable type of the request.\n",
    "    \n",
    "    This function is used by AWS Sagemaker to format a request body that is sent to \n",
    "    the deployed model.\n",
    "    \n",
    "    In order to do this, we must transform the request body into a numpy array and\n",
    "    return that array to be used by the predict_fn function below.\n",
    "    \n",
    "    Note: Often times, you will have need to handle other request_content_types. \n",
    "    However, in this simple case, we are only going to accept text/csv and raise an error \n",
    "    for all other formats.\n",
    "    \"\"\"\n",
    "    if request_content_type == 'text/csv':\n",
    "        samples = []\n",
    "        for r in request_body.split('|'):\n",
    "            samples.append(list(map(float, r.split(','))))\n",
    "        return np.array(samples)\n",
    "    else:\n",
    "        raise ValueError(\"The model only supports text/csv input\")\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    :param input_data: (numpy array) returned array from input_fn above. \n",
    "    :param model (sklearn model) returned model loaded from model_fn above.\n",
    "    \n",
    "    This function is used by AWS Sagemaker to make the prediction on the data\n",
    "    formatted by the input_fn above using the trained model.\n",
    "    \"\"\"\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    \"\"\"\n",
    "    :param prediction: the returned value from predict_fn above.\n",
    "    :param content_type: (string) the content type the endpoint expects to be returned.\n",
    "    \n",
    "    This function reformats the predictions returned from predict_fn to the final\n",
    "    format that will be returned as the API call response.\n",
    "    \n",
    "    Note: Often times, you will have to handle other request_content_types. \n",
    "    \"\"\"\n",
    "    return '|'.join([INDEX_TO_LABEL[idx] for idx in prediction])\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    args = parser.parse_args()\n",
    "    print(args.output_data_dir)\n",
    "    print(args.model_dir)\n",
    "    print(args.train)\n",
    "    print(args.test)\n",
    "    \n",
    "    # Load data from the location specified by args.train (In this case, an S3 bucket)\n",
    "    data = pd.read_csv(os.path.join(args.train,'train.csv'), index_col=0, engine=\"python\")\n",
    "\n",
    "    # Separate input variables and labels\n",
    "    train_X = data[[col for col in data.columns if col != 'label']]\n",
    "    train_Y = data[['label']]\n",
    "\n",
    "    # Convert labels from text to indices\n",
    "    train_Y_enc = train_Y['label'].map(LABEL_TO_INDEX)\n",
    "    print(train_X.head(5))\n",
    "    print(train_Y_enc.head(5))\n",
    "    \n",
    "    # Train the logistic regression model using the fit method\n",
    "    model = LogisticRegression().fit(train_X, train_Y_enc)\n",
    "    \n",
    "    # Save the model to the location specified by args.model_dir\n",
    "    joblib.dump(model, os.path.join(args.model_dir, \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\",\n",
       " '  FutureWarning)',\n",
       " \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\",\n",
       " '  \"this warning.\", FutureWarning)',\n",
       " './output/',\n",
       " './model/',\n",
       " './input/',\n",
       " './input/',\n",
       " '     sepal length  sepal width  petal length  petal width',\n",
       " '104           6.4          2.7           5.3          1.9',\n",
       " '12            7.7          2.8           6.7          2.0',\n",
       " '11            6.0          2.9           4.5          1.5',\n",
       " '144           6.9          3.1           5.1          2.3',\n",
       " '130           4.6          3.2           1.4          0.2',\n",
       " '104    0',\n",
       " '12     0',\n",
       " '11     1',\n",
       " '144    0',\n",
       " '130    2',\n",
       " 'Name: label, dtype: int64']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%!\n",
    "\n",
    "python sg_iris_train.py --output-data-dir ./output/ --model-dir ./model/ --train ./input/ --test ./input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using Sagemaker Estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'arn:aws:iam::892313895307:role/service-role/AmazonSageMaker-ExecutionRole-20200609T132696',\n",
       " 'train_instance_count': 1,\n",
       " 'train_instance_type': 'ml.m4.xlarge',\n",
       " 'train_volume_size': 30,\n",
       " 'train_volume_kms_key': None,\n",
       " 'train_max_run': 86400,\n",
       " 'input_mode': 'File',\n",
       " 'tags': None,\n",
       " 'metric_definitions': None,\n",
       " 'model_uri': None,\n",
       " 'model_channel_name': 'model',\n",
       " 'code_uri': None,\n",
       " 'code_channel_name': 'code',\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7f60eaaf95c0>,\n",
       " 'base_job_name': None,\n",
       " '_current_job_name': None,\n",
       " 'output_path': None,\n",
       " 'output_kms_key': None,\n",
       " 'latest_training_job': None,\n",
       " 'jobs': [],\n",
       " 'deploy_instance_type': None,\n",
       " '_compiled_models': {},\n",
       " 'subnets': None,\n",
       " 'security_group_ids': None,\n",
       " 'encrypt_inter_container_traffic': False,\n",
       " 'train_use_spot_instances': False,\n",
       " 'train_max_wait': None,\n",
       " 'checkpoint_s3_uri': None,\n",
       " 'checkpoint_local_path': None,\n",
       " 'rules': None,\n",
       " 'debugger_hook_config': None,\n",
       " 'tensorboard_output_config': None,\n",
       " 'debugger_rule_configs': None,\n",
       " 'collection_configs': None,\n",
       " 'enable_sagemaker_metrics': None,\n",
       " '_enable_network_isolation': False,\n",
       " 'entry_point': 'sg_iris_train.py',\n",
       " 'git_config': None,\n",
       " 'source_dir': None,\n",
       " 'dependencies': [],\n",
       " 'enable_cloudwatch_metrics': False,\n",
       " 'container_log_level': 20,\n",
       " 'code_location': None,\n",
       " 'image_name': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3',\n",
       " 'uploaded_code': None,\n",
       " '_hyperparameters': {},\n",
       " 'py_version': 'py3',\n",
       " 'framework_version': '0.20.0'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SKLearn estimator by directing it to the sg_iris_train.py script\n",
    "iris_estimator = SKLearn(entry_point='sg_iris_train.py',\n",
    "                         train_instance_type='ml.m4.xlarge',\n",
    "                         role=role)\n",
    "iris_estimator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 01:03:13 Starting - Starting the training job...\n",
      "2020-06-11 01:03:15 Starting - Launching requested ML instances......\n",
      "2020-06-11 01:04:35 Starting - Preparing the instances for training......\n",
      "2020-06-11 01:05:27 Downloading - Downloading input data...\n",
      "2020-06-11 01:06:00 Training - Downloading the training image..\u001b[34m2020-06-11 01:06:21,266 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:21,269 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:21,281 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:21,850 sagemaker-containers INFO     Module sg_iris_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:21,850 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:21,850 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:21,851 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sg-iris-train\n",
      "  Building wheel for sg-iris-train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sg-iris-train (setup.py): finished with status 'done'\n",
      "  Created wheel for sg-iris-train: filename=sg_iris_train-1.0.0-py2.py3-none-any.whl size=7423 sha256=5a0a1b72fa7203d3df0f2501a5cd0874fb548a233d016b883a4bf5eb8438ae5e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lhy_4p6p/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built sg-iris-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sg-iris-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed sg-iris-train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:23,382 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:23,395 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-06-11-01-03-12-645\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-892313895307/sagemaker-scikit-learn-2020-06-11-01-03-12-645/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sg_iris_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sg_iris_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sg_iris_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sg_iris_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-892313895307/sagemaker-scikit-learn-2020-06-11-01-03-12-645/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-06-11-01-03-12-645\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-892313895307/sagemaker-scikit-learn-2020-06-11-01-03-12-645/source/sourcedir.tar.gz\",\"module_name\":\"sg_iris_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sg_iris_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m sg_iris_train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m/opt/ml/output/data\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mNone\n",
      "     sepal length  sepal width  petal length  petal width\u001b[0m\n",
      "\u001b[34m104           6.4          2.7           5.3          1.9\u001b[0m\n",
      "\u001b[34m12            7.7          2.8           6.7          2.0\u001b[0m\n",
      "\u001b[34m11            6.0          2.9           4.5          1.5\u001b[0m\n",
      "\u001b[34m144           6.9          3.1           5.1          2.3\u001b[0m\n",
      "\u001b[34m130           4.6          3.2           1.4          0.2\u001b[0m\n",
      "\u001b[34m104    0\u001b[0m\n",
      "\u001b[34m12     0\u001b[0m\n",
      "\u001b[34m11     1\u001b[0m\n",
      "\u001b[34m144    0\u001b[0m\n",
      "\u001b[34m130    2\u001b[0m\n",
      "\u001b[34mName: label, dtype: int64\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\u001b[0m\n",
      "\u001b[34m2020-06-11 01:06:25,187 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-11 01:06:32 Uploading - Uploading generated training model\n",
      "2020-06-11 01:06:32 Completed - Training job completed\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n"
     ]
    }
   ],
   "source": [
    "# Train the model by passing the path to the S3 bucket containing the training data\n",
    "iris_estimator.fit({'train': 's3://arunprsh-sg-scikit-example/train'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Deploy the model and create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!sagemaker-scikit-learn-2020-06-11-01-03-12-645\n"
     ]
    }
   ],
   "source": [
    "# Deploy model\n",
    "iris_predictor = iris_estimator.deploy(instance_type='ml.m4.xlarge', \n",
    "                                           initial_instance_count=1)\n",
    "\n",
    "# Print the endpoint to test in next step\n",
    "print(iris_predictor.endpoint)\n",
    "\n",
    "# Uncomment and run to terminate the endpoint after you are finished\n",
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test optional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5,2.6,4.4,1.2|5.6,2.9,3.6,1.3|5.6,2.8,4.9,2.0|6.8,2.8,4.8,1.4|5.4,3.9,1.7,0.4|5.7,2.5,5.0,2.0|4.8,3.4,1.6,0.2|5.1,3.8,1.9,0.4|5.7,2.9,4.2,1.3|5.4,3.9,1.3,0.4|5.8,2.7,5.1,1.9|5.6,2.5,3.9,1.1|6.3,2.5,4.9,1.5|6.0,2.9,4.5,1.5|6.7,3.3,5.7,2.5|7.0,3.2,4.7,1.4|6.3,3.3,4.7,1.6|6.5,3.0,5.5,1.8|5.9,3.0,4.2,1.5|6.8,3.0,5.5,2.1|5.1,3.5,1.4,0.2|6.4,3.1,5.5,1.8|5.7,4.4,1.5,0.4|6.1,3.0,4.9,1.8|4.6,3.6,1.0,0.2|5.8,2.6,4.0,1.2|6.1,3.0,4.6,1.4|7.3,2.9,6.3,1.8|4.6,3.1,1.5,0.2|6.9,3.1,5.4,2.1|5.5,4.2,1.4,0.2|7.2,3.2,6.0,1.8|6.1,2.9,4.7,1.4|4.6,3.2,1.4,0.2|6.5,2.8,4.6,1.5|4.4,3.0,1.3,0.2|5.2,3.4,1.4,0.2|6.4,2.7,5.3,1.9|4.8,3.1,1.6,0.2|5.8,2.7,5.1,1.9|5.5,2.3,4.0,1.3|6.9,3.1,4.9,1.5|5.0,3.0,1.6,0.2|4.4,3.2,1.3,0.2|6.7,3.0,5.2,2.3\n",
      "[[5.5 2.6 4.4 1.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.7 3.  5.2 2.3]]\n",
      "[1 1 0 1 2 0 2 2 1 2 0 1 1 1 0 1 1 0 1 0 2 0 2 0 2 1 1 0 2 0 2 0 1 2 1 2 2\n",
      " 0 2 0 1 1 2 2 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.0 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Iris-versicolor|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-setosa|Iris-setosa|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-versicolor|Iris-versicolor|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-virginica|Iris-setosa|Iris-virginica|Iris-setosa|Iris-virginica|Iris-setosa|Iris-versicolor|Iris-versicolor|Iris-virginica|Iris-setosa|Iris-virginica|Iris-setosa|Iris-virginica|Iris-versicolor|Iris-setosa|Iris-versicolor|Iris-setosa|Iris-setosa|Iris-virginica|Iris-setosa|Iris-virginica|Iris-versicolor|Iris-versicolor|Iris-setosa|Iris-setosa|Iris-virginica'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import tarfile\n",
    "import boto3\n",
    "\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'text/csv':\n",
    "        samples = []\n",
    "        for r in request_body.split('|'):\n",
    "            samples.append(list(map(float, r.split(','))))\n",
    "        return np.array(samples)\n",
    "    else:\n",
    "        raise ValueError(\"The model only supports text/csv input\")\n",
    "        \n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    return '|'.join([INDEX_TO_LABEL[idx] for idx in prediction])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_s3_model_to_local(bucket, key, local_model_name):    \n",
    "    s3 = boto3.resource('s3')  \n",
    "    s3.Object(bucket, key).download_file(local_model_name)\n",
    "\n",
    "bucket = 'sagemaker-us-east-1-892313895307'\n",
    "key = 'sagemaker-scikit-learn-2020-06-11-01-03-12-645/output/model.tar.gz'\n",
    "\n",
    "local_model_name = \"iris-model.tar.gz\"\n",
    "\n",
    "download_s3_model_to_local(bucket, key, local_model_name)\n",
    "\n",
    "# uncompress\n",
    "tar = tarfile.open(local_model_name, 'r:gz')\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# load model with joblib\n",
    "trained_model = joblib.load('model.joblib')\n",
    "\n",
    "\n",
    "\n",
    "INDEX_TO_LABEL = {0: 'Iris-virginica', 1: 'Iris-versicolor', 2: 'Iris-setosa'}\n",
    "print(request_body)\n",
    "input_fn_out = input_fn(request_body=request_body, request_content_type=content_type)\n",
    "print(input_fn_out)\n",
    "predict_fn_out = predict_fn(input_fn_out, trained_model)\n",
    "print(predict_fn_out)\n",
    "output_fn_out = output_fn(prediction=predict_fn_out, content_type='text/csv')\n",
    "output_fn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the endpoint using test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the deploy_test data\n",
    "test_data = pd.read_csv('./input/test.csv').values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format test data features\n",
    "request_body = ''\n",
    "for row in test_data:\n",
    "    row = [str(item) for item in row]\n",
    "    row = row[1:-1]\n",
    "    row_string = ','.join(row)\n",
    "    request_body += row_string + '|'\n",
    "request_body = request_body[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.7,3.0,4.2,1.2|5.6,2.7,4.2,1.3|5.6,2.8,4.9,2.0|6.2,2.2,4.5,1.5|6.7,3.0,5.2,2.3|6.0,2.2,4.0,1.0|5.9,3.2,4.8,1.8|5.0,3.4,1.6,0.4|6.4,3.2,5.3,2.3|5.7,3.8,1.7,0.3|6.3,2.8,5.1,1.5|6.0,3.0,4.8,1.8|4.9,2.5,4.5,1.7|7.0,3.2,4.7,1.4|6.5,2.8,4.6,1.5|6.2,2.9,4.3,1.3|4.8,3.4,1.9,0.2|6.8,3.0,5.5,2.1|5.5,2.4,3.7,1.0|5.1,3.7,1.5,0.4|6.9,3.1,5.4,2.1|5.8,2.8,5.1,2.4|6.0,3.4,4.5,1.6|4.6,3.4,1.4,0.3|4.7,3.2,1.6,0.2|5.1,3.5,1.4,0.3|7.4,2.8,6.1,1.9|7.1,3.0,5.9,2.1|7.7,2.6,6.9,2.3|5.0,3.0,1.6,0.2|5.8,2.7,3.9,1.2|6.4,3.1,5.5,1.8|4.4,3.2,1.3,0.2|5.1,3.8,1.5,0.3|6.5,3.0,5.5,1.8|5.1,3.8,1.6,0.2|5.0,3.5,1.6,0.6|5.7,2.9,4.2,1.3|6.7,2.5,5.8,1.8|6.3,2.5,5.0,1.9|4.3,3.0,1.1,0.1|5.2,3.4,1.4,0.2|5.0,2.0,3.5,1.0|6.7,3.0,5.0,1.7|5.6,3.0,4.1,1.3'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sagemaker client using boto3\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "# Specify endpoint and content_type\n",
    "endpoint_name = 'sagemaker-scikit-learn-2020-06-11-01-03-12-645'\n",
    "content_type = 'text/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make call to endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    Body=request_body\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '58a76e62-7172-4c99-8b65-eb2537e0ab73',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '58a76e62-7172-4c99-8b65-eb2537e0ab73',\n",
       "   'x-amzn-invoked-production-variant': 'AllTraffic',\n",
       "   'date': 'Thu, 11 Jun 2020 01:18:05 GMT',\n",
       "   'content-type': 'text/html; charset=utf-8',\n",
       "   'content-length': '645'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ContentType': 'text/html; charset=utf-8',\n",
       " 'InvokedProductionVariant': 'AllTraffic',\n",
       " 'Body': <botocore.response.StreamingBody at 0x7f60ea2de278>}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: Iris-versicolor|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-setosa|Iris-virginica|Iris-virginica|Iris-virginica|Iris-versicolor|Iris-versicolor|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-virginica|Iris-versicolor|Iris-setosa|Iris-setosa|Iris-setosa|Iris-virginica|Iris-virginica|Iris-virginica|Iris-setosa|Iris-versicolor|Iris-virginica|Iris-setosa|Iris-setosa|Iris-virginica|Iris-setosa|Iris-setosa|Iris-versicolor|Iris-virginica|Iris-virginica|Iris-setosa|Iris-setosa|Iris-versicolor|Iris-versicolor|Iris-versicolor\n",
      "Returned:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Iris-versicolor|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-virginica|Iris-versicolor|Iris-virginica|Iris-setosa|Iris-virginica|Iris-setosa|Iris-virginica|Iris-virginica|Iris-virginica|Iris-versicolor|Iris-versicolor|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-versicolor|Iris-setosa|Iris-virginica|Iris-virginica|Iris-virginica|Iris-setosa|Iris-setosa|Iris-setosa|Iris-virginica|Iris-virginica|Iris-virginica|Iris-setosa|Iris-versicolor|Iris-virginica|Iris-setosa|Iris-setosa|Iris-virginica|Iris-setosa|Iris-setosa|Iris-versicolor|Iris-virginica|Iris-virginica|Iris-setosa|Iris-setosa|Iris-versicolor|Iris-versicolor|Iris-versicolor'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "# Print out expected and returned labels\n",
    "print(f\"Expected: {'|'.join([row[-1] for row in test_data])}\")\n",
    "print(\"Returned:\")\n",
    "print()\n",
    "result = response['Body'].read()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
