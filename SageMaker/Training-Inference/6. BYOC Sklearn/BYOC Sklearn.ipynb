{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Train Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train\n"
     ]
    }
   ],
   "source": [
    "%%file train\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Define paths for Model Training inside Container.\n",
    "INPUT_PATH = '/opt/ml/input/data'\n",
    "OUTPUT_PATH = '/opt/ml/output'\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "PARAM_PATH = '/opt/ml/input/config/hyperparameters.json'\n",
    "\n",
    "# Training data sitting in S3 will be copied to this location during training when used with File MODE.\n",
    "TRAIN_DATA_PATH = f'{INPUT_PATH}/train'\n",
    "TEST_DATA_PATH = f'{INPUT_PATH}/test'\n",
    "\n",
    "def train():\n",
    "    print(\"------- [STARTING TRAINING] -------\")\n",
    "    train_df = pd.read_csv(os.path.join(TRAIN_DATA_PATH, 'train.csv'), names=['class', 'mass', 'width', 'height', 'color_score'])\n",
    "    train_df.head()\n",
    "    X_train = train_df[['mass', 'width', 'height', 'color_score']]\n",
    "    y_train = train_df['class']\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Save the trained Model inside the Container\n",
    "    with open(os.path.join(MODEL_PATH, 'model.pkl'), 'wb') as out:\n",
    "        pickle.dump(knn, out)\n",
    "    print(\"------- [TRAINING COMPLETE!] -------\")\n",
    "    \n",
    "    print(\"------- [STARTING EVALUATION] -------\")\n",
    "    test_df = pd.read_csv(os.path.join(TEST_DATA_PATH, 'test.csv'), names=['class', 'mass', 'width', 'height', 'color_score'])\n",
    "    X_test = train_df[['mass', 'width', 'height', 'color_score']]\n",
    "    y_test = train_df['class']\n",
    "    acc = knn.score(X_test, y_test)\n",
    "    print('Accuracy = {:.2f}%'.format(acc * 100))\n",
    "    print(\"------- [EVALUATION DONE!] -------\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Serve Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serve\n"
     ]
    }
   ],
   "source": [
    "%%file serve\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from flask import Flask, Response, request\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "\n",
    "# Singleton Class for holding the Model\n",
    "class Predictor:\n",
    "    model = None\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls):\n",
    "        print('[LOADING MODEL]')\n",
    "        if cls.model is None:\n",
    "            with open(os.path.join(MODEL_PATH, 'model.pkl'), 'rb') as file_:\n",
    "                cls.model = pickle.load(file_)\n",
    "        print('MODEL LOADED!')\n",
    "        return cls.model\n",
    "    \n",
    "    @classmethod\n",
    "    def predict(cls, X):\n",
    "        clf = cls.load_model()\n",
    "        return clf.predict(X)\n",
    "\n",
    "@app.route('/ping', methods=['GET'])\n",
    "def ping():\n",
    "    print('[HEALTH CHECK]')\n",
    "    model = Predictor.load_model()\n",
    "    status = 200\n",
    "    if model is None:\n",
    "        status = 404\n",
    "    return Response(response={\"HEALTH CHECK\": \"OK\"}, status=status, mimetype='application/json')\n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def invoke():\n",
    "    data = None\n",
    "\n",
    "    # Transform Payload in CSV to Pandas DataFrame.\n",
    "    if request.content_type == 'text/csv':\n",
    "        data = request.data.decode('utf-8')\n",
    "        data = StringIO(data)\n",
    "        data = pd.read_csv(data, header=None)\n",
    "    else:\n",
    "        return flask.Response(response='This Predictor only supports CSV data', status=415, mimetype='text/plain')\n",
    "\n",
    "    logging.info('Invoked with {} records'.format(data.shape[0]))\n",
    "    \n",
    "    predictions = Predictor.predict(data)\n",
    "\n",
    "    # Convert from numpy back to CSV\n",
    "    out = StringIO()\n",
    "    pd.DataFrame({'results': predictions}).to_csv(out, header=False, index=False)\n",
    "    result = out.getvalue()\n",
    "\n",
    "    return Response(response=result, status=200, mimetype='text/csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a Docker Image and Push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: byoc-sklearn\n",
      "Account: 892313895307\n",
      "Region: us-east-1\n",
      "Repository: 892313895307.dkr.ecr.us-east-1.amazonaws.com\n",
      "Image URI: 892313895307.dkr.ecr.us-east-1.amazonaws.com/byoc-sklearn:latest\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  136.7kB\r",
      "\r\n",
      "Step 1/8 : FROM python:3.7\n",
      "3.7: Pulling from library/python\n",
      "e4c3d3e4f7b0: Pulling fs layer\n",
      "101c41d0463b: Pulling fs layer\n",
      "8275efcd805f: Pulling fs layer\n",
      "751620502a7a: Pulling fs layer\n",
      "0a5e725150a2: Pulling fs layer\n",
      "397dba5694db: Pulling fs layer\n",
      "88f0c2440f8d: Pulling fs layer\n",
      "788145ec04e5: Pulling fs layer\n",
      "596d3ac3bc76: Pulling fs layer\n",
      "751620502a7a: Waiting\n",
      "788145ec04e5: Waiting\n",
      "397dba5694db: Waiting\n",
      "88f0c2440f8d: Waiting\n",
      "596d3ac3bc76: Waiting\n",
      "101c41d0463b: Verifying Checksum\n",
      "101c41d0463b: Download complete\n",
      "8275efcd805f: Verifying Checksum\n",
      "8275efcd805f: Download complete\n",
      "751620502a7a: Verifying Checksum\n",
      "751620502a7a: Download complete\n",
      "e4c3d3e4f7b0: Verifying Checksum\n",
      "e4c3d3e4f7b0: Download complete\n",
      "397dba5694db: Verifying Checksum\n",
      "397dba5694db: Download complete\n",
      "788145ec04e5: Verifying Checksum\n",
      "788145ec04e5: Download complete\n",
      "596d3ac3bc76: Verifying Checksum\n",
      "596d3ac3bc76: Download complete\n",
      "88f0c2440f8d: Verifying Checksum\n",
      "88f0c2440f8d: Download complete\n",
      "e4c3d3e4f7b0: Pull complete\n",
      "101c41d0463b: Pull complete\n",
      "0a5e725150a2: Verifying Checksum\n",
      "0a5e725150a2: Download complete\n",
      "8275efcd805f: Pull complete\n",
      "751620502a7a: Pull complete\n",
      "0a5e725150a2: Pull complete\n",
      "397dba5694db: Pull complete\n",
      "88f0c2440f8d: Pull complete\n",
      "788145ec04e5: Pull complete\n",
      "596d3ac3bc76: Pull complete\n",
      "Digest: sha256:f9c3459b8bc85236a71eb10d643f6b2eeadddedb2da891795d572843c1436496\n",
      "Status: Downloaded newer image for python:3.7\n",
      " ---> 5b86e11778a2\n",
      "Step 2/8 : COPY requirements.txt ./\n",
      " ---> 8623cb69764a\n",
      "Step 3/8 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Running in 66c42f30f1b5\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.4-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Installing collected packages: numpy, scipy, joblib, threadpoolctl, scikit-learn, six, python-dateutil, pytz, pandas, itsdangerous, MarkupSafe, Jinja2, Werkzeug, click, flask\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0 joblib-0.17.0 numpy-1.19.4 pandas-1.1.4 python-dateutil-2.8.1 pytz-2020.4 scikit-learn-0.23.2 scipy-1.5.3 six-1.15.0 threadpoolctl-2.1.0\n",
      "Removing intermediate container 66c42f30f1b5\n",
      " ---> 00be6a106a8c\n",
      "Step 4/8 : COPY train /usr/local/bin\n",
      " ---> f55d18c34b89\n",
      "Step 5/8 : RUN chmod +x /usr/local/bin/train\n",
      " ---> Running in 42b819c0cde9\n",
      "Removing intermediate container 42b819c0cde9\n",
      " ---> aae62ce0c43b\n",
      "Step 6/8 : COPY serve /usr/local/bin\n",
      " ---> d9408249ae77\n",
      "Step 7/8 : RUN chmod +x /usr/local/bin/serve\n",
      " ---> Running in eaf64814df89\n",
      "Removing intermediate container eaf64814df89\n",
      " ---> 04fc001c0b7c\n",
      "Step 8/8 : EXPOSE 8080\n",
      " ---> Running in cebe7852c951\n",
      "Removing intermediate container cebe7852c951\n",
      " ---> 6990c97b2383\n",
      "Successfully built 6990c97b2383\n",
      "Successfully tagged byoc-sklearn:latest\n",
      "The push refers to repository [892313895307.dkr.ecr.us-east-1.amazonaws.com/byoc-sklearn]\n",
      "032f1a03bf08: Preparing\n",
      "053f064686a0: Preparing\n",
      "59239f9a3c52: Preparing\n",
      "34bf625dab71: Preparing\n",
      "415a4c435e2d: Preparing\n",
      "a9066f74cbd8: Preparing\n",
      "1b17be258ee0: Preparing\n",
      "6522a2852221: Preparing\n",
      "56a69ef72608: Preparing\n",
      "6f7043721c9b: Preparing\n",
      "a933681cf349: Preparing\n",
      "f49d20b92dc8: Preparing\n",
      "fe342cfe5c83: Preparing\n",
      "630e4f1da707: Preparing\n",
      "9780f6d83e45: Preparing\n",
      "a9066f74cbd8: Waiting\n",
      "1b17be258ee0: Waiting\n",
      "6522a2852221: Waiting\n",
      "56a69ef72608: Waiting\n",
      "6f7043721c9b: Waiting\n",
      "a933681cf349: Waiting\n",
      "f49d20b92dc8: Waiting\n",
      "fe342cfe5c83: Waiting\n",
      "630e4f1da707: Waiting\n",
      "9780f6d83e45: Waiting\n",
      "053f064686a0: Pushed\n",
      "59239f9a3c52: Pushed\n",
      "34bf625dab71: Pushed\n",
      "032f1a03bf08: Pushed\n",
      "6522a2852221: Pushed\n",
      "a9066f74cbd8: Pushed\n",
      "1b17be258ee0: Pushed\n",
      "6f7043721c9b: Pushed\n",
      "56a69ef72608: Pushed\n",
      "fe342cfe5c83: Pushed\n",
      "630e4f1da707: Pushed\n",
      "f49d20b92dc8: Pushed\n",
      "9780f6d83e45: Pushed\n",
      "415a4c435e2d: Pushed\n",
      "a933681cf349: Pushed\n",
      "latest: digest: sha256:a2ebe6e788d472b87131c8ee6e7ef75d3e2cb27b01d9f1d41d6d4e88274d0e5e size: 3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Assign a name for your Docker image.\n",
    "image_name=byoc-sklearn\n",
    "echo \"Image Name: ${image_name}\" \n",
    "\n",
    "# Retrieve AWS Account.\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-east-1 if none defined).\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "echo \"Account: ${account}\" \n",
    "echo \"Region: ${region}\"\n",
    "\n",
    "repository=\"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "echo \"Repository: ${repository}\" \n",
    "\n",
    "image=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"Image URI: ${image}\" \n",
    "\n",
    "# If the repository does not exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names ${image_name} > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name ${image_name} > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly.\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${repository}\n",
    "\n",
    "# Build the docker image locally with the image name and tag it.\n",
    "docker build -t ${image_name} .\n",
    "docker tag ${image_name} ${image}\n",
    "\n",
    "# Finally, push image to ECR with the full image name.\n",
    "docker push ${image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "import pandas as pd\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "image_name = 'byoc-sklearn'\n",
    "image_uri = f'{account}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train (Local Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "model = sagemaker.estimator.Estimator(\n",
    "    image_name=image_uri,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='local',\n",
    "    sagemaker_session=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmperx397pr_algo-1-dd9yi_1 ... \n",
      "\u001b[1BAttaching to tmperx397pr_algo-1-dd9yi_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-dd9yi_1  |\u001b[0m ------- [STARTING TRAINING] -------\n",
      "\u001b[36malgo-1-dd9yi_1  |\u001b[0m ------- [TRAINING COMPLETE!] -------\n",
      "\u001b[36malgo-1-dd9yi_1  |\u001b[0m ------- [STARTING EVALUATION] -------\n",
      "\u001b[36malgo-1-dd9yi_1  |\u001b[0m Accuracy = 97.73%\n",
      "\u001b[36malgo-1-dd9yi_1  |\u001b[0m ------- [EVALUATION DONE!] -------\n",
      "\u001b[36mtmperx397pr_algo-1-dd9yi_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "model.fit({'train': 'file://.././DATA/train.csv', 'test': 'file://.././DATA/test.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy (Locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpm093izjl_algo-1-g5u49_1\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m  * Serving Flask app \"serve\" (lazy loading)\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m  * Environment: production\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m \u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m \u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m  * Debug mode: off\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m  * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m [HEALTH CHECK]\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m [LOADING MODEL]\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m MODEL LOADED!\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m 172.18.0.1 - - [04/Nov/2020 00:16:46] \"\u001b[37mGET /ping HTTP/1.1\u001b[0m\" 200 -\n",
      "!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(1, 'local', endpoint_name='byoc-sklearn', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Real Time Inference (Locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.././DATA/test.csv', header=None)\n",
    "test_df = df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1.021429</td>\n",
       "      <td>1.117647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2    3         4\n",
       "5  3  1.021429  1.117647  0.8  0.441176"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.021429</td>\n",
       "      <td>1.117647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2    3         4\n",
       "5  1.021429  1.117647  0.8  0.441176"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(test_df.columns[[0]], axis=1, inplace=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.02142857, 1.11764706, 0.8       , 0.44117647]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m [LOADING MODEL]\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m MODEL LOADED!\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m 172.18.0.1 - - [04/Nov/2020 00:18:22] \"\u001b[37mPOST /invocations HTTP/1.1\u001b[0m\" 200 -\n",
      "\u001b[36malgo-1-g5u49_1  |\u001b[0m INFO:werkzeug:172.18.0.1 - - [04/Nov/2020 00:18:22] \"\u001b[37mPOST /invocations HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "prediction = predictor.predict(test_df.values).decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train (using SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '.././DATA'\n",
    "\n",
    "train_data_s3_pointer = session.upload_data(f'{WORK_DIRECTORY}/train', key_prefix='byoc-sklearn/train')\n",
    "test_data_s3_pointer = session.upload_data(f'{WORK_DIRECTORY}/test', key_prefix='byoc-sklearn/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-892313895307/byoc-sklearn/train'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_s3_pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-892313895307/byoc-sklearn/test'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_s3_pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "model = sagemaker.estimator.Estimator(\n",
    "    image_name=image_uri,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.xlarge',\n",
    "    sagemaker_session=session  # ensure the session is set to session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04 17:32:19 Starting - Starting the training job...\n",
      "2020-11-04 17:32:21 Starting - Launching requested ML instances.........\n",
      "2020-11-04 17:33:52 Starting - Preparing the instances for training...\n",
      "2020-11-04 17:34:27 Downloading - Downloading input data......\n",
      "2020-11-04 17:35:31 Training - Downloading the training image...\n",
      "2020-11-04 17:36:19 Uploading - Uploading generated training model\n",
      "2020-11-04 17:36:19 Completed - Training job completed\n",
      "\u001b[34m------- [STARTING TRAINING] -------\u001b[0m\n",
      "\u001b[34m------- [TRAINING COMPLETE!] -------\u001b[0m\n",
      "\u001b[34m------- [STARTING EVALUATION] -------\u001b[0m\n",
      "\u001b[34mAccuracy = 97.73%\u001b[0m\n",
      "\u001b[34m------- [EVALUATION DONE!] -------\u001b[0m\n",
      "Training seconds: 112\n",
      "Billable seconds: 112\n"
     ]
    }
   ],
   "source": [
    "model.fit({'train': train_data_s3_pointer, 'test': test_data_s3_pointer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Trained Model as SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(1, 'ml.m5.xlarge', endpoint_name='byoc-sklearn', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Time Inference using Deployed Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.././DATA/test/test.csv', header=None)\n",
    "test_df = df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.970588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4\n",
       "12  0.342857  0.382353  0.553846  0.970588"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(test_df.columns[[0]], axis=1, inplace=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34285714, 0.38235294, 0.55384615, 0.97058824]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(test_df.values).decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform (Batch Inference) using Trained SageMaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: byoc-sklearn-2020-11-04-17-32-19-621\n"
     ]
    }
   ],
   "source": [
    "bucket_name = session.default_bucket()\n",
    "output_path = f's3://{bucket_name}/byoc-sklearn/batch_test_out'\n",
    "\n",
    "transformer = model.transformer(instance_count=1, \n",
    "                                instance_type='ml.m5.xlarge', \n",
    "                                output_path=output_path, \n",
    "                                assemble_with='Line', \n",
    "                                accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '.././DATA'\n",
    "\n",
    "batch_input = session.upload_data(f'{WORK_DIRECTORY}/batch_test', key_prefix='byoc-sklearn/batch_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Gracefully stopping... (press Ctrl+C again to force)\n",
      ".........................\n",
      "\u001b[34m * Serving Flask app \"serve\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[34mINFO:werkzeug:169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[34mINFO:werkzeug:169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m * Serving Flask app \"serve\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35mINFO:werkzeug:169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35mINFO:werkzeug:169.254.255.130 - - [04/Nov/2020 18:01:34] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(batch_input, content_type='text/csv', split_type='Line', input_filter='$')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Batch Transformed Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = session.boto_session.client('s3')\n",
    "s3_client.download_file(bucket_name, \n",
    "                        'byoc-sklearn/batch_test_out/batch_test.csv.out', \n",
    "                        '.././DATA/batch_test/batch_test.csv.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform results: \n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('.././DATA/batch_test/batch_test.csv.out', 'r') as f:\n",
    "    results = f.readlines()   \n",
    "    \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
